{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a989cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def add_nearest_src_root(start: Path) -> Path:\n",
    "    \"\"\"Add the nearest ancestor containing a `src/` directory to sys.path.\n",
    "\n",
    "    Args:\n",
    "        start: Starting path for the upward search.\n",
    "\n",
    "    Returns:\n",
    "        The path inserted into sys.path.\n",
    "\n",
    "    Raises:\n",
    "        RuntimeError: If no ancestor with a `src` directory is found.\n",
    "    \"\"\"\n",
    "    current: Path = start.resolve()\n",
    "\n",
    "    for parent in (current, *current.parents):\n",
    "        if (parent / \"src\").is_dir():\n",
    "            sys.path.insert(0, str(parent))\n",
    "            return parent\n",
    "\n",
    "    raise RuntimeError(\"No ancestor directory containing 'src/' found\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT: Path = add_nearest_src_root(start=Path.cwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1803b318",
   "metadata": {},
   "source": [
    "**Import dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71e1469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20260103-023542\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from src.data.load_utils import DataModule, load_datamodule_2010to2024\n",
    "from src.models.models.TCN.interface import TCN\n",
    "from src.models.utils import clean_model_saves, save_results\n",
    "\n",
    "time: str = datetime.now().strftime(format=\"%Y%m%d-%H%M%S\")\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eac8f0",
   "metadata": {},
   "source": [
    "**Aquire the train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module: DataModule = load_datamodule_2010to2024()\n",
    "train_data: pl.DataFrame = data_module.extract_dataframe(\n",
    "    inferior_percentile=0.0, superior_percentile=0.8\n",
    ")\n",
    "test_data: pl.DataFrame = data_module.extract_dataframe(\n",
    "    inferior_percentile=0.0, superior_percentile=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6fc0d",
   "metadata": {},
   "source": [
    "**Instantiate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size: int = len(train_data.columns)\n",
    "output_mask: Tensor = torch.tensor(\n",
    "    data=[*(True for _ in range(12)), *(False for _ in range(19))]\n",
    ")\n",
    "lookback: int = 52\n",
    "\n",
    "TCN_model: TCN = TCN(\n",
    "    feature_size=feature_size,\n",
    "    output_mask=output_mask,\n",
    "    temporal_lookback=lookback,\n",
    "    temporal_horizon=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1a99a",
   "metadata": {},
   "source": [
    "**Evaluate the raw model on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd28c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"mae\": 0.687454803423448,\n",
      "  \"mape\": 1.88456212473916,\n",
      "  \"mse\": 1.0003617007832426,\n",
      "  \"rmse\": 0.8956050885307205,\n",
      "  \"smape\": 1.7151300365274602\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results: dict[str, Any] = TCN_model.evaluate(\n",
    "    test_data=test_data,\n",
    "    batch_size=16,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(json.dumps(obj=results, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4940095b",
   "metadata": {},
   "source": [
    "**Train the model on the train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a951d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 30/30 [00:02<00:00, 10.26it/s, horizon=1, loss=0.843028, lr=1.91e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.342826, eval: 0.396259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 30/30 [00:02<00:00, 10.97it/s, horizon=1, loss=0.519482, lr=3.97e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.343712, eval: 0.395529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 30/30 [00:03<00:00,  9.25it/s, horizon=1, loss=0.245270, lr=7.17e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.339711, eval: 0.394109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 30/30 [00:03<00:00,  9.94it/s, horizon=1, loss=0.376758, lr=1.12e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.341688, eval: 0.394559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 30/30 [00:00<00:00, 123.99it/s, horizon=1, loss=0.190211, lr=1.57e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.341444, eval: 0.392746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 30/30 [00:02<00:00, 10.37it/s, horizon=1, loss=0.369455, lr=2.01e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.336048, eval: 0.392990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 30/30 [00:03<00:00,  7.91it/s, horizon=1, loss=0.175951, lr=2.41e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.333923, eval: 0.385625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 30/30 [00:02<00:00, 10.50it/s, horizon=1, loss=0.272617, lr=2.73e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.329206, eval: 0.382362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 30/30 [00:02<00:00, 10.27it/s, horizon=1, loss=0.243470, lr=2.93e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.320747, eval: 0.401051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 30/30 [00:02<00:00, 10.06it/s, horizon=1, loss=0.366026, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.308890, eval: 0.395795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 30/30 [00:02<00:00, 10.47it/s, horizon=1, loss=0.263512, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.288113, eval: 0.425895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 30/30 [00:03<00:00,  9.18it/s, horizon=1, loss=0.451960, lr=3.00e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.265582, eval: 0.488214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 30/30 [00:03<00:00,  8.75it/s, horizon=1, loss=0.204143, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.242830, eval: 0.492695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 30/30 [00:02<00:00, 10.24it/s, horizon=1, loss=0.206330, lr=2.99e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.217550, eval: 0.502746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 30/30 [00:00<00:00, 320.16it/s, horizon=1, loss=0.202649, lr=2.98e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.202595, eval: 0.545425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 30/30 [00:02<00:00, 10.51it/s, horizon=1, loss=0.168837, lr=2.97e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.183688, eval: 0.572710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 30/30 [00:02<00:00, 10.32it/s, horizon=1, loss=0.150125, lr=2.96e-04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SmoothL1Loss (huber) loss] train: 0.173072, eval: 0.624531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100:  37%|███▋      | 11/30 [00:01<00:01, 10.69it/s, horizon=1, loss=0.162566, lr=2.95e-04]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m train: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mTCN_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/src/models/models/TCN/interface.py:83\u001b[39m, in \u001b[36mTCN.fit\u001b[39m\u001b[34m(self, train_data)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Train the model on the given data.\"\"\"\u001b[39;00m\n\u001b[32m     76\u001b[39m dataloader: TorchDataLoader = acquire_train_data(\n\u001b[32m     77\u001b[39m     train_dataframe=train_data,\n\u001b[32m     78\u001b[39m     output_mask=\u001b[38;5;28mself\u001b[39m._output_mask,\n\u001b[32m     79\u001b[39m     lookback=\u001b[38;5;28mself\u001b[39m._temporal_lookback,\n\u001b[32m     80\u001b[39m     train_config=\u001b[38;5;28mself\u001b[39m._train_config,\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[43mtrain_TCN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train_config\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/src/models/models/TCN/train.py:319\u001b[39m, in \u001b[36mtrain_TCN\u001b[39m\u001b[34m(model, dataloader, train_config)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mint\u001b[39m(y_target.shape[\u001b[32m0\u001b[39m]) == \u001b[38;5;28mint\u001b[39m(x.shape[\u001b[32m0\u001b[39m])\n\u001b[32m    317\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m y_hat: Tensor = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, out_features)\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m y_hat.ndim == \u001b[32m2\u001b[39m, (\n\u001b[32m    321\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected y_hat (batch, out_features). \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(y_hat.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mint\u001b[39m(y_hat.shape[\u001b[32m0\u001b[39m]) == \u001b[38;5;28mint\u001b[39m(y_target.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/src/models/models/TCN/model.py:240\u001b[39m, in \u001b[36mTCN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m x.ndim == \u001b[32m3\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mExpected (batch, lookback, in_features)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m x_c: Tensor = x.transpose(dim0=\u001b[32m1\u001b[39m, dim1=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# (batch, in_features, lookback)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m z: Tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_c\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, channels, lookback)\u001b[39;00m\n\u001b[32m    241\u001b[39m last: Tensor = z[:, :, -\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# (batch, channels)\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._head(last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/src/models/models/TCN/model.py:156\u001b[39m, in \u001b[36mTemporalBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    148\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m    149\u001b[39m \n\u001b[32m    150\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    154\u001b[39m \u001b[33;03m        Tensor of shape (batch, out_channels, length).\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     y: Tensor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     y = \u001b[38;5;28mself\u001b[39m._act1(y)\n\u001b[32m    158\u001b[39m     y = \u001b[38;5;28mself\u001b[39m._drop1(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/src/models/models/TCN/model.py:88\u001b[39m, in \u001b[36mCausalConv1d.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m \u001b[33;03m    Tensor of shape (batch, out_channels, length).\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m x_padded: Tensor = nn.functional.pad(\n\u001b[32m     83\u001b[39m     \u001b[38;5;28minput\u001b[39m=x,\n\u001b[32m     84\u001b[39m     pad=(\u001b[38;5;28mself\u001b[39m._pad_left, \u001b[32m0\u001b[39m),\n\u001b[32m     85\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     86\u001b[39m     value=\u001b[32m0.0\u001b[39m,\n\u001b[32m     87\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_padded\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:371\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data/xai/final-project-miguel-montes-lorenzo/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:366\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    356\u001b[39m         F.pad(\n\u001b[32m    357\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    364\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train: bool = True\n",
    "if train:\n",
    "    TCN_model.fit(train_data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ae01a",
   "metadata": {},
   "source": [
    "**Evaluate the trained model on the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468970cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"mae\": 0.6937545958932463,\n",
      "  \"mape\": 2.1142150997281908,\n",
      "  \"mse\": 1.0053599720651454,\n",
      "  \"rmse\": 0.9005714834153236,\n",
      "  \"smape\": 1.7018879335243384\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results: dict[str, Any] = TCN_model.evaluate(\n",
    "    test_data=test_data,\n",
    "    batch_size=16,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(json.dumps(obj=results, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b69928",
   "metadata": {},
   "source": [
    "**Save the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462bea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "path: Path = PROJECT_ROOT / \"models\" / \"TCN\" / time\n",
    "save_results(results=results, store_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165f8ed",
   "metadata": {},
   "source": [
    "**Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9794c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path: Path = PROJECT_ROOT / \"models\" / \"TCN\" / time\n",
    "TCN_model.save(store_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160034f2",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path: Path = PROJECT_ROOT / \"models\" / \"TCN\" / time\n",
    "TCN_model.load(store_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d931dc",
   "metadata": {},
   "source": [
    "**Clean TCN model saves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04540335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove every directory under model_path whiout a .keep file under it\n",
    "# e.g. <model_path>/<dir>/.keep -> dont remove <dir>\n",
    "clean: bool = False\n",
    "if clean:\n",
    "    path: Path = PROJECT_ROOT / \"models\" / \"TCN\"\n",
    "    clean_model_saves(model_path=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project-miguel-montes-lorenzo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
